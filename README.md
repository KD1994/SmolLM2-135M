# TODO:

- [X] scaled dot product attention
- [X] torch.compile
- [X] weight sharing/typing
- [X] autocast (float16/bfloat16)
- [X] GradScaler
